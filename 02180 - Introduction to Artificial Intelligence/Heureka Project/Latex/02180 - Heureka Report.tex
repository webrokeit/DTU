\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{titling}
\usepackage{fancyhdr}
\usepackage[latin1]{inputenc}
\usepackage{enumerate}
\usepackage{float}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[labelfont=bf]{caption}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{listings}
\usepackage{geometry}
\usepackage{fancyref}
\usepackage{hyperref}
\usepackage{framed}
\usepackage[hypcap]{caption}
\usepackage[toc,page]{appendix}
\parindent=0pt
\frenchspacing

\pagestyle{fancy}

\newcommand{\pctlrepeat}[1]{{\buildrel{#1}\over\curvearrowleft}}
\newcommand{\tbox}[1] {\begin{tabular}{| c |}\hline {#1} \\ \hline\end{tabular}}


\fancyhead[L]{\slshape\footnotesize May 12, 2014\\\textsc{02180 Introduction to Artificial Intelligence}}
\fancyhead[R]{\slshape\footnotesize \textsc{Andreas Kjeldsen (s092638)}\\\textsc{Morten Eskesen (s133304)}}
\fancyfoot[C]{\thepage}

\lstdefinestyle{logoutput}{
	backgroundcolor=\color[RGB]{248,248,248},
	tabsize=1,
	captionpos=b
  	belowcaptionskip=1\baselineskip,
  	breaklines=true,
  	frame=single,
	language={},
  	basicstyle=\footnotesize\ttfamily\color{Black},
	mathescape
}
\newcommand{\tab}{\hspace*{2em}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\begin{titlepage}
\begin{center}

\includegraphics[scale=2.0]{GFX/dtu_logo.pdf}\\[1cm]

\textsc{\LARGE Technical University of Denmark}\\[1cm]

\textsc{\Large 02180 Introduction to Artificial Intelligence 2014}\\[0.5cm]


% Title
\HRule \\[0.4cm]
{\huge \bfseries Heureka Project}\\[0.1cm]
\HRule \\[1cm]

% Author and supervisor
\large
\emph{Authors:}
\\[10pt]
Andreas Hallberg \textsc{Kjeldsen}\\
\emph{s092638@student.dtu.dk}
\\[10pt]
Morten Chabert \textsc{Eskesen}\\
\emph{s133304@student.dtu.dk}\\[1cm]

{\large May 12, 2014}\\[1.5cm]
\end{center}

\begin{center}
	\textbf{Abstract}
\end{center}
Abstract goes here..



\end{titlepage}

\section{Introduction}
\label{sec:intro}
This report will focus on our work on the \emph{Heureka Project}, given as an assignment in the DTU course \emph{02180 Introduction to Artificial Intelligence}. The Heureka Project focuses on graph searching, logical deduction and the heuristics.

\subsection{Objectives}
The two objectives for the project are:
\begin{enumerate}
	\item[] \textbf{Route Planning}\\
	Be able to find a route within a map.
	
	\item[] \textbf{Logical Deduction}\\
	Be able to deduce whether a query is satisfied using a knowledge base, either as a direct proof or as a refutation proof. 
\end{enumerate}

\section{Data Representation}
To solve both objectives, we decided to represent our data as graphs. The reasoning behinds this decision, is that a graph can both represent a map and a knowledge base.

\subsection{Map}
For the route planning problem, we are expecting a source file containing the map data. The source file is read and interpreted, generating a directed graph representing the map. Each node represents a coordinate pair {\tt (X, Y)} indicating either a crossing of two streets or an end of a street. Each edge has a name, a weight and represents a partial street. Edge names are not unique, as a street can consist of multiple edges.

\subsubsection{Source File}
The source file should be in plaintext, have one entry per line and use the following syntax:
\begin{itemize}
	\item \tbox{\tt X1 Y1 StreetName X2 Y2}\\
	Where {\tt (X1, Y1)} and {\tt (X2, Y2)} are node coordinates and {\tt StreetName} is the edge name. The weight of the edge is then calculated as the straight line distance from {\tt (X1, Y1)} to {\tt (X2, Y2)}.
\end{itemize}

\subsection{Knowledge Base}
For the logical deduction problem, we are expecting a source file containing the knowledge base. The source file is read and interpreted, generating a directed graph representing the knowledge base.

\subsubsection{Source File}
The source file should be in plaintext, have one entry per line and use one of the following syntaxes:
\begin{itemize}
	\item \tbox{\tt Literal}\\
	Where {\tt Literal} is the ID of the literal. When a literal is stated alone, it is interpreted as being a fact and always satisfiable.
	
	\item \tbox{\tt Literal$_1$ if Literal$_2$ [ $\ldots$ Literal$_n$]}\\
	Where {\tt Literal$_1$, Literal$_2$ $\ldots$ Literal$_n$} are the IDs of the literals. {\tt Literal$_1$} is satisfied if {\tt Literal$_2$ $\ldots$ Literal$_n$} are satisfied. There must be at least one literal to depend on, there is no specific upper limit.
	
	\item \tbox{\tt Literal$_1$ Literal$_2$  [ $\ldots$ Literal$_n$]}\\
	Where {\tt Literal$_1$, Literal$_2$ $\ldots$ Literal$_n$} are the IDs of the literals. Literals listed this way, are being interpreted as a disjunction of the literals. There must be listed at least two literals.
\end{itemize}

Literals can be stated as negative by prepending their ID with a {\tt !}, example:\\ \tbox{\tt !Literal$_1$ if Literal$_2$ !Literal$_3$}

\subsubsection{Nodes}
In the knowledge base, nodes can represent different objects:
\begin{description}
	\item[Literal] Literals are what the knowledge base works with. Literals can be {\tt Positive} and {\tt Negative}, they have a unique ID. A negative literal has a {\tt !} prepended to it's ID, which means literal {\tt lit} is a positive literal and literal {\tt !lit} is a negative literal. Literals can be stated as facts, if the positive literal is a fact, the negative literal cannot be, as this would make the knowledge base inconsistent.
	
	\item[Conjunctive Literal] Literals can depend on more than one other literal to be satisfied. In this case we make a node representing the conjunction of the depending literals. The ID of the conjunction will be the IDs of the depending literals in sorted order separated by {\tt \&}. An edge is then made between the literal and the conjunction, and between the conjunction and the literals it represents. If all the literals of a conjunction are facts, then so will the conjunction be.
	
	\item[Disjunctive Literal] In cases where a literal has more than one way to be satisfied, a disjunctive literal can be used. The ID of the disjunction will be the IDs of the literals in sorted order separated by {\tt |}. An edge is made between the literal and the disjunction, and between the disjunction and the literals it represents. If any of the literals in the disjunction are facts, then so will the disjunction be.
\end{description}

The nodes are stored in the graph as either {\tt AND} nodes or {\tt OR} nodes. An {\tt AND} node is satisfied if all all nodes it connects to are satisfied. An {\tt OR} node is satisfied if any of the nodes it connects to are satisfied. The scheme for determining the node type is:
$$
\text{Node type} = \begin{cases}
  {\text{\tt AND}} & \text{if {\tt Negative} or {\tt Conjunctive}} \\
  {\text {\tt OR}} & \text{if {\tt Positive} or {\tt Disjunctive}}
\end{cases}
$$

\subsubsection{Edges}
In the knowledge base, edges represent a dependency. If node $n_1$ has an edge to node $n_2$ it indicates that $n_1$ depends on $n_2$.

\section{Route Planning}
For the route planning problem, we wanted to focus on finding an optimal route according to distance. Our solution does not take speeding limits into considerations nor routes requiring payment (bridges, ferries etc.).

\subsection{Initiating A Search}
To initiate a search, a start node and an end node must be specified. The start and end node are identified by giving two street names and then finding the node corresponding to the crossing of the two streets.

\subsection{Finding A Route}
We chose to use the A* algorithm, with the straight line distance (henceforth \emph{SLD}) as our heuristic function. The SLD heuristic can only be applied if the triangle inequality is satisfied, therefore we assume that the data set supplied satisfies this. Further the SLD heuristic is both admissible and monotonic.\\
\\
The A* algorithm makes use of a priority queue to keep track of which node to expand next. The priority queue prioritizes the nodes based on their score, where their score is the cost of going to the node + the SLD to the goal node. The priority queue should be able to update values, due to the scenario when a node is found multiple times, the best possible score should be used. To support this, we implemented a priority queue using a binary heap supported by a dictionary. This gave us the possibility of making constant time look ups, and cutdown value updates by $O(n)$ time.

\subsection{Example Run}
Running our route planner on Data Set '\nameref{subsec:oneway}' (see \ref{subsec:oneway}), using the corner of {\tt SktPedersStraede} and {\tt Larsbjoernsstraede} as starting point, and the corner of {\tt Studiestraede} and {\tt Larsbjoernsstraede} as ending point, gave the following result:
\begin{lstlisting}[style=logoutput]
SktPedersStraede -> LarslejStraede -> Noerrevoldgade ->
Vestervoldgade -> Studiestraede
\end{lstlisting}

\section{Logical Deduction}


\section{Conclusion}
We have managed to encode the data sets for both problems as graphs, making it possible to use the same code to solve both problems.

\subsection{Route Planning}
Our route planner works, it's fast and finds an optimal route according to distance. An improvement would be to include speeding limits on the roads, this would make it possible to plan the route according to traveling time instead of distance, or even make a hybrid that would take both into consideration. It would also be advantageous to include bridges, ferries and the like, also stating the cost of using these.

\subsection{Logical Deduction}

\clearpage
\pagenumbering{Roman}
\begin{appendices}

\section{Data Sets}
Below are some of the data sets we used for testing.

\subsection{Route Planning}
\subsubsection{One-way Streets}
\label{subsec:oneway}
\lstinputlisting[style=logoutput]{../Heureka/TestInputs/pathtestinput01.txt}

\section{Knowledge Base Illustrations}
Below are some illustrations of the graphs used by the knowledge base. The illustrations are generated using Graphviz \footnote{Graphviz - Graph Visualization Software:  \url{http://www.graphviz.org/}.}

\subsection{Breakfast Example}
Breakfast example goes here.
\end{appendices}

\end{document}
